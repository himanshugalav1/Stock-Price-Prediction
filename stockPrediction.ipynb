{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "stock_data = pd.read_csv('./NFLX.csv',index_col='Date')\n",
    "stock_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "\n",
    "def plot_curve(dates, data1, lab1, data2, lab2, xlab, ylab):\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter ('%Y-%m-%d'))\n",
    "    plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=60))\n",
    "    x_dates = [dt.datetime.strptime(d, '%d-%b-%y').date() for d in dates]\n",
    "    plt.plot(x_dates, data1, label=lab1)\n",
    "    plt.plot(x_dates, data2, label=lab2)\n",
    "    plt.xlabel(xlab)\n",
    "    plt.ylabel(ylab)\n",
    "    plt.legend()\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curve(dates=stock_data.index.values, \n",
    "           data1=stock_data['High'], lab1='High', \n",
    "           data2=stock_data['Low'], lab2='Low', \n",
    "           xlab='Time Scale', ylab='Scaled USD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_y = stock_data['Close']    # target is close\n",
    "X_feat = stock_data.iloc[:,0:3]   # input parameters are open, high, low\n",
    "\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "stock_data_ft = sc.fit_transform(X_feat.values)\n",
    "stock_data_ft = pd.DataFrame(columns=X_feat.columns, data=stock_data_ft, index=X_feat.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_split(data, n_steps):\n",
    "    x, y = [], []\n",
    "    for i in range(len(data)-n_steps+1):\n",
    "        x.append(data[i:i + n_steps, : -1])  # taking only open and high of n_steps rows\n",
    "        y.append(data[i + n_steps-1, -1])\n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = lstm_split(stock_data_ft.values, n_steps=2)\n",
    "\n",
    "train_split = 0.2\n",
    "split_idx = int(np.ceil(len(x1)*train_split))\n",
    "date_index = stock_data_ft.index\n",
    "X_train, X_test = x1[split_idx:], x1[:split_idx]\n",
    "y_train, y_test = y1[split_idx:], y1[:split_idx]\n",
    "X_train_date, X_test_date = date_index[split_idx:], date_index[:split_idx]\n",
    "print(x1.shape, X_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = Sequential()\n",
    "lstm.add(LSTM(32, input_shape=(X_train.shape[1], X_train.shape[2]), activation='relu', return_sequences=True))\n",
    "lstm.add(LSTM(32, activation='relu'))\n",
    "lstm.add(Dense(1))\n",
    "lstm.compile(loss= 'mean_squared_error', optimizer='adam')\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = lstm.fit(X_train, y_train, epochs=100, batch_size=4, verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lstm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test.shape)\n",
    "print(y_test[0])\n",
    "print(len(y_pred))\n",
    "print(y_pred[0])\n",
    "\n",
    "print(X_test_date.shape)\n",
    "print(X_test_date[0], X_test_date[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curve(dates=X_test_date, \n",
    "           data1=y_test, lab1='True Value', \n",
    "           data2=y_pred, lab2='LSTM Value', \n",
    "           xlab='Time Scale', ylab='Scaled USD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsme = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(\"RSME: \", rsme)\n",
    "print(\"MAPE: \", mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for LSTM with more parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = Sequential()\n",
    "lstm.add(LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), activation='relu', return_sequences=True))\n",
    "lstm.add(LSTM(64, activation='relu'))\n",
    "lstm.add(Dense(1))\n",
    "lstm.compile(loss= 'mean_squared_error', optimizer='adam')\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = lstm.fit(X_train, y_train, epochs=100, batch_size=4, verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lstm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curve(dates=X_test_date, \n",
    "           data1=y_test, lab1='True Value', \n",
    "           data2=y_pred, lab2='LSTM Value', \n",
    "           xlab='Time Scale', ylab='Scaled USD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsme = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(\"RSME: \", rsme)\n",
    "print(\"MAPE: \", mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with increased window size(history) to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = lstm_split(stock_data_ft.values, n_steps=10)\n",
    "\n",
    "train_split = 0.2\n",
    "split_idx = int(np.ceil(len(x1)*train_split))\n",
    "date_index = stock_data_ft.index\n",
    "X_train, X_test = x1[split_idx:], x1[:split_idx]\n",
    "y_train, y_test = y1[split_idx:], y1[:split_idx]\n",
    "X_train_date, X_test_date = date_index[split_idx:], date_index[:split_idx]\n",
    "print(x1.shape, X_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = Sequential()\n",
    "lstm.add(LSTM(32, input_shape=(X_train.shape[1], X_train.shape[2]), activation='relu', return_sequences=True))\n",
    "lstm.add(LSTM(32, activation='relu'))\n",
    "lstm.add(Dense(1))\n",
    "lstm.compile(loss= 'mean_squared_error', optimizer='adam')\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = lstm.fit(X_train, y_train, epochs=100, batch_size=4, verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lstm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test.shape)\n",
    "print(y_test[0])\n",
    "print(len(y_pred))\n",
    "print(y_pred[0])\n",
    "\n",
    "print(X_test_date.shape)\n",
    "print(X_test_date[0], X_test_date[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curve(dates=X_test_date, \n",
    "           data1=y_test, lab1='True Value', \n",
    "           data2=y_pred, lab2='LSTM Value', \n",
    "           xlab='Time Scale', ylab='Scaled USD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsme = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(\"RSME: \", rsme)\n",
    "print(\"MAPE: \", mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for LSTM with more parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = Sequential()\n",
    "lstm.add(LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), activation='relu', return_sequences=True))\n",
    "lstm.add(LSTM(64, activation='relu'))\n",
    "lstm.add(Dense(1))\n",
    "lstm.compile(loss= 'mean_squared_error', optimizer='adam')\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = lstm.fit(X_train, y_train, epochs=100, batch_size=4, verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lstm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curve(dates=X_test_date, \n",
    "           data1=y_test, lab1='True Value', \n",
    "           data2=y_pred, lab2='LSTM Value', \n",
    "           xlab='Time Scale', ylab='Scaled USD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsme = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(\"RSME: \", rsme)\n",
    "print(\"MAPE: \", mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.8\n",
    "split_idx = int(np.ceil(len(stock_data)*train_split))\n",
    "train = stock_data[['Close']].iloc[:split_idx]\n",
    "test = stock_data[['Close']].iloc[split_idx:]\n",
    "test_pred = np.array([train.rolling(10).mean().iloc[-1]]*len(test)).reshape((-1,1))\n",
    "\n",
    "print( 'Test RMSE: %.3f' % mean_squared_error(test, test_pred, squared=False))\n",
    "print('Test MAPE: %.3f' % mean_absolute_percentage_error(test, test_pred))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(test)\n",
    "plt.plot(test_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import SimpleExpSmoothing\n",
    "\n",
    "X = stock_data[['Close']].values\n",
    "train_split = 0.8\n",
    "split_idx = int(np.ceil(len(X)*train_split))\n",
    "train = X[:split_idx]\n",
    "test = X[split_idx:]\n",
    "test_concat = np.array([]).reshape((0,1))\n",
    "\n",
    "for i in range(len(test)):\n",
    "    train_fit = np.concatenate((train, np.asarray(test_concat)))\n",
    "    fit = SimpleExpSmoothing(np.asarray(train_fit)).fit(smoothing_level=0.2, optimized=False)\n",
    "    test_pred = fit. forecast(1)\n",
    "    test_concat = np.concatenate((np.asarray(test_concat), test_pred.reshape((-1,1))))\n",
    "\n",
    "print('Test RMSE: %.3f' % mean_squared_error(test, test_concat, squared=False))\n",
    "print('Test MAPE: %.3f' % mean_absolute_percentage_error(test, test_concat) )\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(test)\n",
    "plt.plot(test_pred)\n",
    "plt.plot(test_concat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
